services:
  inference_server:
    build: 
        context: .
        dockerfile: Dockerfile
    container_name: lenetmodel
    ports:
      - "5000:5000"
    environment:
      - MODEL_PATH=best_model.h5
      - PORT=5000
    restart: unless-stopped